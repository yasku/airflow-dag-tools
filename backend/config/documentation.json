{
  "sections": [
    {
      "id": "test-section",
      "title": "Secci\u00f3n de Prueba",
      "icon": "M12 6v6m0 0v6m0-6h6m-6 0H6",
      "cards": [
        {
          "title": "EST\u00c1NDAR DE DESARROLLO EN AIRFLOW",
          "content": "Aspectos a considerar al momento de desarrollar rutinas que luego pasar\u00e1n a producci\u00f3n.  \nToda rutina que no cumpla con este est\u00e1ndar ser\u00e1 devuelta al \u00e1rea de desarrollo de Big Data & Analytics para su ajuste.",
          "markdownContent": "## Introducci\u00f3n\n\nA continuaci\u00f3n se detallan los aspectos a considerar al momento de desarrollar rutinas que luego pasar\u00e1n a producci\u00f3n.  \nToda rutina que no cumpla con este est\u00e1ndar ser\u00e1 devuelta al \u00e1rea de desarrollo de Big Data & Analytics para su ajuste.\n\n---\n\n## Nomenclatura de Rutinas\n\n**Formato:**\n\n```\nGRUPO_proceso_prefijo_nnx.sql\n```\n\n### Definiciones:\n- **grupo:** N\u00famero de grupo asignado al proceso (solicitado v\u00eda HP Service Manager al grupo ARQUITECTURA-DW).\n  - `A`: Airflow\n  - `C`: Cloudera (posible migraci\u00f3n a Airflow)\n  - `G`: RAC8/Ctrl-m (posible migraci\u00f3n a Airflow)\n\n- **proceso:** Identifica el proceso en desarrollo (obligatorio).\n- **prefijo:** Operaci\u00f3n que se realiza (opcional).\n- **nn:** Nivel de actualizaci\u00f3n del script (obligatorio). Valores v\u00e1lidos:\n  - `01`: Creaci\u00f3n de objetos (tablas, \u00edndices, particiones, DML).\n  - `05`: Eliminaci\u00f3n de tablas auxiliares del proceso (DROP o TRUNCATE).\n\n### Comandos:\n\n**DROP en RAC8:**\n```sql\nBEGIN\n    EXECUTE IMMEDIATE 'DROP TABLE {{esquema_rac8}}.{{table_name}} PURGE';\nEXCEPTION\n    WHEN OTHERS THEN\n        IF SQLCODE != -942 THEN\n            RAISE;\n        END IF;\nEND;\n```\n\n**DROP en Cloudera:**\n```sql\nDROP TABLE IF EXISTS {{esquema_impala}}.{{table_name}} PURGE;\nDROP VIEW IF EXISTS {{esquema_impala}}.{{view_name}};\n```\n\n- **x:** Letra que define el orden de ejecuci\u00f3n (`a`, `b`, ..., `z`, `aa`, `ab`, ...).\n\n**Ejemplo:**  \n`A0323_trafico_clientes_pec_mes_01a.sql`\n\n**Observaci\u00f3n:**  \nLos scripts deben escribirse en min\u00fascula, excepto la letra del grupo.\n\n---\n\n## Nomenclatura de Directorios\n\nLa arquitectura de carpetas en Airflow est\u00e1 definida en el documento: `Est\u00e1ndar Airflow v2.5`.\n\n---\n\n## Arquitectura del Ciclo de Ejecuci\u00f3n en Airflow\n\n### Scripts\n\nEstructura recomendada:\n```sql\n-- ****************************************************************\n-- Archivo....: A0323_trafico_clientes_pec_mes_01f.sql\n-- Autor......: Waisman Gabriel\n-- Descripci\u00f3n: Inserta los datos de la tabla CONSUMO_TRAFICO_NAV_MB_MES\n-- ****************************************************************\n\n-- Historia del Proceso\n-- Fecha       Por             Descripci\u00f3n\n-- 24/04/2023  Waisman Gabriel Creaci\u00f3n del Script\n\n-- ****************************************************************\n-- Par\u00e1metros\n-- Parametro: [ESQUEMA] - Valor: [{{params.esquema_rac8}}]\n-- Parametro: [FECHA]   - Valor: [{{ds}}]\n-- Parametro: [PAIS]    - Valor: [{{params.pais}}]\n```\n\n---\n\n### DAGS\n\n**Importaci\u00f3n de librer\u00edas:**\n```python\nfrom datetime import datetime, timedelta\nfrom airflow import DAG\nfrom airflow.operators.dummy_operator import DummyOperator\nfrom mod_oracle_query import Run_Oracle\nfrom mod_cloudera_query import Run_Cloudera\nimport os\nimport pendulum\n```\n\n**Par\u00e1metros del DAG:**\n```python\nDAG_ID = os.path.basename(__file__).replace(\".pyc\", \"\").replace(\".py\", \"\")\nSCHEDULE_INTERVAL = \"@daily\"\nDAG_OWNER_NAME = \"Nombre del Autor\"\nALERT_EMAIL_ADDRESSES = [\"correos@claro.com.ar\"]\nTIMEZONE = Variable.get(\"timezone_AR\")\nSTART_DATE = pendulum.datetime(yyyy, mm, dd, tz=TIMEZONE)\n\ndefault_args = {\n    'owner': DAG_OWNER_NAME,\n    'depends_on_past': True,\n    'wait_for_downstream': True,\n    'start_date': START_DATE,\n    'email': ALERT_EMAIL_ADDRESSES,\n    'email_on_failure': True,\n    'email_on_retry': False,\n    'retries': 3,\n    'retry_delay': timedelta(minutes=10),\n    'catchup': True\n}\n```\n\n**Definici\u00f3n del DAG:**\n```python\ndag = DAG(\n    DAG_ID,\n    default_args=default_args,\n    schedule_interval=SCHEDULE_INTERVAL,\n    tags=['Carpeta: DataWarehouse', 'DW'],\n    max_active_runs=1,\n    concurrency=1,\n    is_paused_upon_creation=False\n)\n```\n\n---\n\n### Par\u00e1metros del DAG (opcional)\n```python\nvariables_etl_a = {\n    'esquema_impala': 'prod_AR',\n    'esquema_rac8': 'RACING.',\n    'pais': 'AR',\n    'table_name': 'AUX_A0323_CONS_TRAF_CLI_A'\n}\n```\n\n---\n\n## Flujo de Ejecuci\u00f3n\n\n```python\ndef dummy_task(task_id, dag):\n    return DummyOperator(\n        task_id=task_id,\n        depends_on_past=True,\n        wait_for_downstream=True,\n        dag=dag\n    )\n\ndef eliminarTablasAuxiliares():\n    drop1 = Run_Cloudera.generate_etl_operator_ar(...)\n    drop2 = ...\n    endDrop = dummy_task('endDrop', dag)\n    [drop1, drop2, ...] >> endDrop\n    return endDrop\n\nwith dag:\n    start = dummy_task('start', dag)\n    end = dummy_task('end', dag)\n    ejecucionDrop = eliminarTablasAuxiliares()\n    ejecucionProc = ejecutarProceso(start)\n    ejecucionProc >> end\n```\n\n---\n\n## M\u00f3dulos SQL\n\n### Oracle (RAC8)\n\n- `generate_etl_operation(...)`\n- `generate_etl_query(...)`\n- `insert_dataframe_oracle(...)`\n\n### Cloudera\n\n- `generate_etl_operator_pais(...)`  \n  Pa\u00edses: `AR`, `UY`, `PY`.\n\n---\n\n## Dependencias\n\n**mod_dependencia:**\n- `operator_sensor_cloudera_sql(...)`\n- `operator_sensor_oracle(...)`\n\nEjemplo SQL Sensor:\n```sql\nSELECT CASE WHEN CONDICION THEN true ELSE false END\nFROM NOMBRE_TABLA\nGROUP BY ...\nHAVING ...\n```\n\n---\n\n## Uso de TAGs\n\n**Tags de \u00e1rea:**\n- `DW`, `ArqDW`, `RP`, `OT`\n\n**Tags de carpeta:**\n- `Carpeta: DataWarehouse`, `Carpeta: Replica`, etc.\n\n**Tags de origen/destino:**\n- `BDOri: PROD`\n- `BDDes: RAC8`\n\n**Ejemplo:**\n```python\ntags=['Carpeta: Replica', 'RP', 'BDOri: PROD', 'BDDes: RAC8']\n```\n\n---\n\n## Actualizaci\u00f3n Diccionario de Datos (RAC8 / GEN8)\n\n**RAC8:**\n```sql\nUPDATE actualizacion_racing\nSET act_actualiz_date = SYSDATE,\n    act_old_date = act_actualiz_date\nWHERE act_table_name = 'CUSTOMER_BASE_NUEVO';\n```\n\n**GEN8:**\n```sql\nUPDATE ACTUALIZACION_GENESIS\nSET act_actualiz_date = SYSDATE,\n    act_old_date = act_actualiz_date\nWHERE act_table_name = 'B_ASE_INGRESOS_PP_CR';\n```\n\n---\n\n## Versiones\n\n- **1.0** \u2013 25/04/2023 \u2013 Documento inicial (N. Nu\u00f1ez y G. Waisman)  \n- **2.0** \u2013 17/10/2023 \u2013 Agregado uso de `pendulum` y m\u00e1s m\u00f3dulos  \n- **3.0** \u2013 15/08/2024 \u2013 Agregado: actualizaci\u00f3n de diccionario en RAC8  "
        },
        {
          "title": "Nuevo documento",
          "content": "Contenido del documento..."
        },
        {
          "title": "Nuevo documentoasdas",
          "content": "Contenido del documento...asdsad",
          "markdownContent": "Contenido del documento...asdad"
        }
      ]
    },
    {
      "id": "buenas-practicas-1918",
      "title": "Buenas Practicas",
      "icon": "M9 12l2 2 4-4m5.618-4.016A11.955 11.955 0 0112 2.944a11.955 11.955 0 01-8.618 3.04A12.02 12.02 0 003 9c0 5.591 3.824 10.29 9 11.622 5.176-1.332 9-6.03 9-11.622 0-1.042-.133-2.052-.382-3.016z",
      "cards": [
        {
          "title": "Nuevo documento",
          "content": "Escribe un breve resumen aqu\u00ed...",
          "markdownContent": "# Nuevo documento\n\nEscribe tu contenido con formato Markdown aqu\u00ed..."
        }
      ]
    }
  ]
}