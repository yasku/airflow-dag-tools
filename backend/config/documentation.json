{
  "sections": [
    {
      "id": "getting-started",
      "title": "Empezando",
      "icon": "M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z",
      "cards": [
        {
          "title": "Estandar de Desarrollo en AirFlow.",
          "content": "# Est\u00e1ndar de Desarrollo para Rutinas de Big Data & Analytics\n\n## Introducci\u00f3n\n\nEl presente documento establece los criterios y est\u00e1ndares a seguir durante el desarrollo de rutinas que se implementar\u00e1n en ambientes productivos. El cumplimiento de estos lineamientos es **obligatorio** para garantizar un pasaje exitoso a Producci\u00f3n.\n\n> \u26a0\ufe0f **Importante**: Las rutinas que no cumplan con este est\u00e1ndar ser\u00e1n devueltas al \u00e1rea de desarrollo de Big Data & Analytics para realizar los ajustes necesarios.\n\n## 1. Nomenclatura de Rutinas\n\nLas rutinas deben seguir este formato estandarizado:\n\n```\nGRUPO_proceso_prefijo_nnx.sql\n```\n\n### Descripci\u00f3n de componentes:\n\n| Componente | Obligatorio | Descripci\u00f3n |\n|------------|:-----------:|-------------|\n| **grupo** | \u2705 | N\u00famero de grupo asignado al proceso. Debe solicitarse v\u00eda HP Service Manager al grupo ARQUITECTURA-DW durante la etapa de an\u00e1lisis. |\n| **proceso** | \u2705 | Identifica el proceso en desarrollo. |\n| **prefijo** | \u274c | Opcional. Identifica la operaci\u00f3n que se realiza. |\n| **nn** | \u2705 | Nivel de actualizaci\u00f3n del script (valores aceptados: 01, 05). |\n| **x** | \u2705 | Orden de ejecuci\u00f3n (a-z, excluyendo ch-\u00f1-ll). |\n\n### Tipos de grupos:\n- **Grupos tipo A**: Procesos desarrollados en Airflow.\n- **Grupos tipo C**: Procesos desarrollados en Cloudera (pueden ser migrados a Airflow).\n- **Grupos tipo G**: Procesos desarrollados en RAC8/Ctrl-m (pueden ser migrados a Airflow).\n\n### Niveles de actualizaci\u00f3n (nn):\n- **01**: Creaci\u00f3n de objetos (tablas, \u00edndices, particiones) o sentencias DML.\n- **05**: Eliminaci\u00f3n de tablas auxiliares del proceso o truncate. Debe ubicarse al principio y fin de la secuencia.\n\n### Ejemplo:\n```\nA0323_trafico_clientes_pec_mes_01a.sql\n```\n\n> \ud83d\udcdd **Observaci\u00f3n**: Los nombres de los scripts deben estar en min\u00fasculas, excepto la letra del grupo.\n\n## 2. Comandos para Operaciones DDL\n\n### DROP TABLE en RAC8:\n```sql\nBEGIN\n    EXECUTE IMMEDIATE 'DROP TABLE {{esquema_rac8}}.{{table_name}} PURGE';\nEXCEPTION\n    WHEN OTHERS THEN\n        IF SQLCODE != -942 THEN\n            RAISE;\n        END IF;\nEND;\n```\n\n### DROP VIEW en RAC8:\n```sql\nBEGIN\n    EXECUTE IMMEDIATE 'DROP VIEW {{esquema_rac8}}.{{view_name}}';\nEXCEPTION\n    WHEN OTHERS THEN\n        IF SQLCODE != -942 THEN\n            RAISE;\n        END IF;\nEND;\n```\n\n### DROP TABLE en Cloudera:\n```sql\nDROP TABLE IF EXISTS {{esquema_impala}}.{{table_name}} PURGE;\n```\n\n### DROP VIEW en Cloudera:\n```sql\nDROP VIEW IF EXISTS {{esquema_impala}}.{{view_name}};\n```\n\n## 3. Arquitectura/Nomenclatura de Directorios\n\nLa nomenclatura de los directorios y la arquitectura en Airflow est\u00e1 definida en el \"Est\u00e1ndar Airflow v2.5\".\n\n## 4. Arquitectura del Ciclo de Ejecuci\u00f3n de Airflow\n\n### 4.1 Estructura de Scripts SQL\n\nTodo script SQL debe incluir un encabezado con la siguiente estructura:\n\n```sql\n-- ****************************************************************\n-- Archivo....: A0323_trafico_clientes_pec_mes_01f.sql\n-- Autor......: Waisman Gabriel\n--\n-- Descripci\u00f3n: Inserta los datos de la tabla\n--              CONSUMO_TRAFICO_NAV_MB_MES para la fecha indicada\n--\n-- ****************************************************************\n-- Historia del Proceso\n--\n-- Fecha      Por               Descripci\u00f3n\n-- ********** ***************   ***********************************\n-- 24/04/2023 Waisman Gabriel   Creaci\u00f3n del Script\n--\n-- ****************************************************************\n-- Par\u00e1metros\n-- ****************************************************************\n-- Parametro: [ESQUEMA]     - Valor: [{{params.esquema_rac8}}]\n-- Parametro: [FECHA]       - Valor: [{{ds}}]\n-- Parametro: [PAIS]        - Valor: [{{params.pais}}]\n-- ****************************************************************\n-- Inserta los datos en la tabla CONSUMO_TRAFICO_NAV_MB_MES\n-- ****************************************************************\n```\n\n### 4.2 Estructura de DAGs\n\nLos DAGs deben estructurarse siguiendo este patr\u00f3n:\n\n#### 4.2.1 Definici\u00f3n inicial de m\u00f3dulos o librer\u00edas\n\n```python\n# -*- coding: utf-8 -*-\nfrom datetime import datetime, timedelta\nfrom airflow import DAG\nfrom airflow.operators.dummy_operator import DummyOperator\nfrom mod_oracle_query import Run_Oracle\nfrom mod_cloudera_query import Run_Cloudera\nimport os\nimport pendulum\n```\n\n#### 4.2.2 Definici\u00f3n y parametrizaci\u00f3n del DAG\n\n```python\n\"\"\"\nDefinicion y parametrizacion del Dag\n\"\"\"\nDAG_ID = os.path.basename(__file__).replace(\".pyc\", \"\").replace(\".py\", \"\")\n# How often to Run. @daily - Once a day at Midnight\nSCHEDULE_INTERVAL = \"@daily\"\nDAG_OWNER_NAME = \"Nombre del Autor\"\n# List of email address to send email alerts to if this job fails\nALERT_EMAIL_ADDRESSES = [\"correos@claro.com.ar\"]\nTIMEZONE = Variable.get(\"timezone_AR\")\nSTART_DATE=pendulum.datetime(yyyy,mm,dd, tz=TIMEZONE)\n\ndefault_args = {\n    'owner': DAG_OWNER_NAME,\n    'depends_on_past': True,\n    'wait_for_downstream': True,\n    'start_date':  SCHEDULE_INTERVAL,\n    'email': ALERT_EMAIL_ADDRESSES,\n    'email_on_failure': True,\n    'email_on_retry': False,\n    'retries': 3,\n    'retry_delay': timedelta(minutes=10),\n    'catchup': True\n}\n\ndag = DAG(\n        DAG_ID,\n        default_args=default_args,\n        schedule_interval=SCHEDULE_INTERVAL,\n        tags=['Carpeta: DataWarehouse', 'DW'],\n        max_active_runs=1,\n        concurrency=1,\n        is_paused_upon_creation=False\n)\n```\n\n#### 4.2.3 Par\u00e1metros adicionales (Opcional)\n\n```python\n# Parametros\nvariables_etl_a = {\n    'esquema_impala': 'prod_AR',\n    'esquema_rac8': 'RACING.',\n    'pais': 'AR',\n    'table_name': 'AUX_A0323_CONS_TRAF_CLI_A'\n}\n```\n\n#### 4.2.4 Definici\u00f3n de Operadores\n\n```python\n\"\"\"\nOperadores e implementaci\u00f3n del flujo de ejecuci\u00f3n\n\"\"\"\ndef dummy_task(task_id,dag):\n    task = DummyOperator(\n        task_id='{t}'.format(t=task_id),\n        depends_on_past=True,\n        wait_for_downstream=True,\n        dag=dag)\n    return task\n\ndef eliminarTablasAuxiliares():\n    drop_AUX_A0323_CONS_TRAF_CLI_A = Run_Cloudera.generate_etl_operator_ar('DROP_AUX_A0323_CONS_TRAF_CLI_A','A0323_trafico_clientes_pec_mes_05a.sql',variables_etl_a,sql_files_path)\n    drop_AUX_A0323_CONS_TRAF_CLI_B = Run_Cloudera.generate_etl_operator_ar('DROP_AUX_A0323_CONS_TRAF_CLI_B','A0323_trafico_clientes_pec_mes_05a.sql',variables_etl_b,sql_files_path)\n    drop_AUX_A0323_CONS_TRAF_CLI_C = Run_Cloudera.generate_etl_operator_ar('DROP_AUX_A0323_CONS_TRAF_CLI_C','A0323_trafico_clientes_pec_mes_05a.sql',variables_etl_c,sql_files_path)\n    truncate_CONSUMO_TRAFICO_NAV_MB_MES = Run_Cloudera.generate_etl_operator_ar('TRUNCATE_CONSUMO_TRAFICO_NAV_MB_MES','A0323_trafico_clientes_pec_mes_05b.sql',variables_etl,sql_files_path)\n    endDrop = dummy_task('endDrop',dag)\n    [drop_AUX_A0323_CONS_TRAF_CLI_A, drop_AUX_A0323_CONS_TRAF_CLI_B, drop_AUX_A0323_CONS_TRAF_CLI_C, truncate_CONSUMO_TRAFICO_NAV_MB_MES] >> endDrop\n    return endDrop\n```\n\n#### 4.2.5 Flujo de ejecuci\u00f3n\n\n```python\n\"\"\"\nFlujo de ejecuci\u00f3n\n\"\"\"\nwith dag:\n    start = dummy_task('start',dag)\n    end = dummy_task('end',dag)\n    ejecucionDrop = eliminarTablasAuxiliares()\n    ejecucionDrop >> start\n    ejecucionProc = ejecutarProceso(start)\n    ejecucionProc >> end\n```\n\n## 5. M\u00f3dulos para Ejecuci\u00f3n de Sentencias SQL\n\n### 5.1 RAC8: `mod_oracle_query.Run_Oracle`\n\n#### 5.1.1 `generate_etl_operation(nom_task, files, connection_id, carpeta, variables_etl)`\n\nEjecuta una sentencia SQL de Oracle desde un archivo.\n\n| Par\u00e1metro | Descripci\u00f3n |\n|-----------|-------------|\n| `nom_task` | Nombre de la tarea |\n| `files` | Nombre del archivo SQL |\n| `connection_id` | Conexi\u00f3n a la base de datos |\n| `carpeta` | Variable que contiene la ubicaci\u00f3n de los archivos SQL |\n| `variables_etl` | Variables extras (no macros de Airflow) |\n\n#### 5.1.2 `generate_etl_query(nom_task, sql_query, connection_id)`\n\nEjecuta una sentencia SQL de Oracle directamente.\n\n| Par\u00e1metro | Descripci\u00f3n |\n|-----------|-------------|\n| `nom_task` | Nombre de la tarea |\n| `sql_query` | Consulta SQL a realizar |\n| `connection_id` | Conexi\u00f3n a la base de datos |\n\n#### 5.1.3 `insert_dataframe_oracle(df_fin, table, connection_id)`\n\nInserta un dataframe en una tabla de Oracle.\n\n| Par\u00e1metro | Descripci\u00f3n |\n|-----------|-------------|\n| `df_fin` | Dataframe a insertar |\n| `table` | Tabla destino |\n| `connection_id` | Conexi\u00f3n a la base de datos |\n\n### 5.2 CLOUDERA: `mod_cloudera_query.Run_Cloudera`\n\n#### 5.2.1 `generate_etl_operator_PAIS(nom_tarea, files, etl_args, carpeta)`\n\nEjecuta una sentencia SQL en Cloudera para un pa\u00eds espec\u00edfico (AR, UY, PY).\n\n| Par\u00e1metro | Descripci\u00f3n |\n|-----------|-------------|\n| `nom_tarea` | Nombre de la tarea |\n| `files` | Nombre del archivo SQL |\n| `etl_args` | Variables extras (no macros de Airflow) |\n| `carpeta` | Variable que contiene la ubicaci\u00f3n de los archivos SQL |\n\n### 5.3 Dependencias: `mod_dependencia.Run_Sensor`\n\n#### 5.3.1 `operator_sensor_cloudera_sql(nom_tarea, sql, esquema_pais, poke_interval, timeout)`\n\nSensor tipo PythonSensor para ejecutar consultas SQL en Cloudera.\n\n| Par\u00e1metro | Descripci\u00f3n |\n|-----------|-------------|\n| `nom_tarea` | Nombre de la tarea |\n| `sql` | Consulta SQL a ejecutar (debe retornar True o False) |\n| `esquema_pais` | Esquema del pa\u00eds para la ejecuci\u00f3n |\n| `poke_interval` | Duraci\u00f3n en segundos entre reintentos (t\u00edpicamente 1800s) |\n| `timeout` | Tiempo m\u00e1ximo de espera para reintentos (t\u00edpicamente 5400s) |\n\n**Ejemplo de script SQL:**\n```sql\nSELECT CASE WHEN CONDICION_AFIRMATIVA THEN true\n       ELSE false END\nFROM NOMBRE_TABLA\nWHERE (Si es que hace falta) \nGROUP BY (Si es que hace falta)  \nHAVING (Si es que hace falta);\n```\n\n#### 5.3.2 `operator_sensor_oracle(filename, nom_tarea, connection_id, parametros, carpeta, poke_interval, timeout)`\n\nSensor tipo SqlSensor para ejecutar scripts SQL en Oracle.\n\n| Par\u00e1metro | Descripci\u00f3n |\n|-----------|-------------|\n| `filename` | Nombre del archivo de control |\n| `nom_tarea` | Nombre de la tarea |\n| `connection_id` | Conexi\u00f3n a la base de datos Oracle |\n| `parametros` | Par\u00e1metros para el script |\n| `carpeta` | Variable de ruta |\n| `poke_interval` | Duraci\u00f3n en segundos entre reintentos (t\u00edpicamente 1800s) |\n| `timeout` | Tiempo m\u00e1ximo de espera para reintentos (t\u00edpicamente 5400s) |\n\n## 6. Etiquetas (TAGS)\n\nPara una mejor organizaci\u00f3n, b\u00fasqueda y soporte, se deben definir etiquetas en dos categor\u00edas:\n\n### 6.1 Estructura/\u00e1rea de trabajo\n\n**Prefijos:**\n- **DataWarehouse**: DW\n- **ArqDW**: ArqDW\n- **Replica**: RP\n- **Otro**: OT\n\n### 6.2 Carpeta\n\nIndica la ubicaci\u00f3n del DAG en la estructura de directorios:\n- Carpeta: DataWarehouse\n- Carpeta: Replica\n- Carpeta: ArqDW\n- Carpeta: AplicacionesIT\n\n### 6.3 Origen y Destino\n\nSe debe especificar el origen y destino de la informaci\u00f3n:\n- BDOri: PROD\n- BDDes: RAC8\n\n### Ejemplo de definici\u00f3n de TAGs:\n\n```python\ndag = DAG(\n        DAG_ID,\n        default_args=default_args,\n        schedule_interval=SCHEDULE_INTERVAL,\n        tags=['Carpeta: Replica','RP','BDOri: PROD','BDDes: RAC8'],\n        max_active_runs=1,\n        concurrency=1,\n        is_paused_upon_creation=False)\n```\n\n## 7. Actualizaci\u00f3n de Diccionario de Datos\n\n### 7.1 RAC8\n\nDespu\u00e9s de actualizar una tabla, se debe actualizar la tabla del diccionario de datos:\n\n```sql\nUPDATE actualizacion_racing\nSET act_actualiz_date = SYSDATE\n   ,act_old_date = act_actualiz_date\nWHERE act_table_name = 'CUSTOMER_BASE_NUEVO'\n/\n```\n\n### 7.2 GEN8\n\n```sql\nUPDATE ACTUALIZACION_GENESIS\nSET act_actualiz_date = SYSDATE\n   ,act_old_date = act_actualiz_date\nWHERE act_table_name = 'B_ASE_INGRESOS_PP_CR'\n/\n```\n\n---\n\n## Historial de Versiones\n\n| Versi\u00f3n | Fecha | Descripci\u00f3n |\n|---------|-------|-------------|\n| 1.0 | 25/04/2023 | Documento inicial creado por Nicolas Nu\u00f1ez y Gabriel Waisman |\n| 2.0 | 17/10/2023 | Agregado librer\u00eda Pendulum para configuraci\u00f3n UTC, m\u00e1s m\u00f3dulos |\n| 3.0 | 15/08/2024 | Agregado actualizaci\u00f3n de diccionario en RAC8 |\n"
        },
        {
          "title": "Primeros Pasos",
          "content": "Contenido de primeros pasos..."
        }
      ]
    },
    {
      "id": "best-practices",
      "title": "Buenas Pr\u00e1cticas",
      "icon": "M9 12l2 2 4-4m5.618-4.016A11.955 11.955 0 0112 2.944a11.955 11.955 0 01-8.618 3.04A12.02 12.02 0 003 9c0 5.591 3.824 10.29 9 11.622 5.176-1.332 9-6.03 9-11.622 0-1.042-.133-2.052-.382-3.016z",
      "cards": [
        {
          "title": "Mejores Pr\u00e1cticas",
          "content": "Contenido de mejores pr\u00e1cticas..."
        }
      ]
    }
  ]
}